{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca42ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "from scipy.stats import chi2\n",
    "import math\n",
    "import arch\n",
    "import time\n",
    "import pygosolnp\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fe504e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygosolnp\n",
      "  Downloading pygosolnp-2021.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting pysolnp\n",
      "  Downloading pysolnp-2022.3.13-cp39-cp39-win_amd64.whl (484 kB)\n",
      "Installing collected packages: pysolnp, pygosolnp\n",
      "Successfully installed pygosolnp-2021.5.1 pysolnp-2022.3.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pygosolnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "059d942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_mean_test(data, true_mu=0, conf_level=0.95):\n",
    "    ''' Perfom a t-Test if mean of distribution:\n",
    "         - null hypothesis (H0) = zero\n",
    "         - alternative hypothesis (H1) != zero\n",
    "         \n",
    "        Parameters:\n",
    "            data (dataframe):   pnl (distribution of profit and loss) or return\n",
    "            true_mu (float):    expected mean of distribuition\n",
    "            conf_level (float): test confidence level\n",
    "        Returns:\n",
    "            answer (dict):      statistics and decision of the test\n",
    "    '''\n",
    "\n",
    "    significance = 1-conf_level\n",
    "    \n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data, ddof=1)\n",
    "    \n",
    "    t = (mean - true_mu)/(std/np.sqrt(len(data)))\n",
    "    '''p<0.05, 2-tail'''\n",
    "    t_padrao = stats.t.ppf(1-round(significance/2,4), len(data)-1)\n",
    "    pvalue = stats.ttest_1samp(data, popmean=true_mu, alternative='two-sided')[-1]\n",
    "    H0 = \"Mean of distribution = 0\"\n",
    "    if pvalue > significance: #ou t < np.abs(t_padrao): \n",
    "        decision = \"Fail to rejected H0.\"\n",
    "    else:\n",
    "        decision = \"Reject H0.\"\n",
    "\n",
    "    answer = {\"null hypothesis\":H0,\n",
    "              \"decision\":decision,\n",
    "              \"t-test statistc\":t,\n",
    "              \"t-tabuladed\":t_padrao,\n",
    "              \"p-value\":pvalue}\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14caca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration_test(violations, conf_level=0.95):\n",
    "    \n",
    "    '''Perform the Christoffersen and Pelletier Test (2004) called Duration Test.\n",
    "        The main objective is to know if the VaR model responds quickly to market movements\n",
    "         in order to do not form volatility clusters.\n",
    "        Duration is time betwenn violations of VaR.\n",
    "        This test verifies if violations has no memory i.e. should be independent.\n",
    "        \n",
    "        Parameters:\n",
    "            violations (series): series of violations of VaR\n",
    "            conf_level (float):  test confidence level\n",
    "        Returns:\n",
    "            answer (dict):       statistics and decision of the test\n",
    "    '''\n",
    "    if isinstance(violations, pd.core.series.Series):\n",
    "        N = violations[violations==0].count()\n",
    "        first_hit = violations.iloc[0]\n",
    "        last_hit = violations.iloc[-1]\n",
    "    elif isinstance(violations, pd.core.frame.DataFrame):\n",
    "        N = violations[violations==0].count().values[0]\n",
    "        first_hit = violations.iloc[0][0]\n",
    "        last_hit = violations.iloc[-1][0]\n",
    "        \n",
    "    duration = [i for i, x in enumerate(violations) if x==1]\n",
    "    \n",
    "    diff_duration = np.diff(duration)\n",
    "    \n",
    "    TN = len(violations)\n",
    "    C = np.zeros(len(diff_duration))\n",
    "    \n",
    "    if not duration:\n",
    "        D=np.array([0,0])\n",
    "        C=np.array([0,0])\n",
    "    \n",
    "    if first_hit==0 and duration:\n",
    "        C = np.append(1,C)\n",
    "        D = np.append(duration[0], diff_duration) #days until first violation\n",
    "        \n",
    "    if last_hit==0 and duration:\n",
    "        C = np.append(C, 1)\n",
    "        D = np.append(D, TN-duration[-1]-1)\n",
    "        \n",
    "    if N>0 and duration: N = len(D)-1\n",
    "    else: N=0\n",
    "      \n",
    "    def likDurationW(x, D, C, N):\n",
    "        b = x\n",
    "        a = ( (N - C[0] - C[N])/(sum(D**b)) )**(1/b)\n",
    "        lik = C[0]* np.log(pweibull(D[0],a,b,survival=True)) + (1-C[0]) * dweibull(D[0], a, b, log = True) +\\\n",
    "            sum(dweibull(D[1:(N-1)], a, b, log = True) ) + C[N]*np.log(pweibull(D[N],a,b,survival = True) )  +\\\n",
    "                (1 - C[N]) *dweibull(D[N], a, b, log = True)\n",
    "                \n",
    "        if np.isnan(lik) or np.isinf(lik): \n",
    "            lik = 1e10\n",
    "        else: lik = -lik\n",
    "        return lik  \n",
    "    \n",
    "    # When b=1 we get the exponential\n",
    "    def dweibull(D, a, b, log=False):\n",
    "        # density of Weibull\n",
    "        pdf = b * np.log(a) + np.log(b) + (b - 1) * np.log(D) - (a * D)**b\n",
    "        if not log: pdf = np.exp(pdf)\n",
    "        return pdf\n",
    "    \n",
    "    def pweibull(D, a, b, survival = False):\n",
    "        # distribution of Weibull\n",
    "        cdf = 1 - np.exp(-(a*D)**b)\n",
    "        if survival: cdf = 1 - cdf\n",
    "        return cdf\n",
    "    \n",
    "    optimizedBetas = optimize.minimize(likDurationW, x0=[2], args=(D, C, N), method=\"L-BFGS-B\",\n",
    "                                       bounds= [(0.001, 10)] )\n",
    "    \n",
    "    print(optimizedBetas.message)\n",
    "    \n",
    "    b = optimizedBetas.x\n",
    "    uLL = -likDurationW(b, D, C, N)\n",
    "    rLL = -likDurationW(1, D, C, N)\n",
    "    LR = 2*(uLL - rLL)\n",
    "    LRp = 1 - chi2.cdf(LR, 1)\n",
    "    \n",
    "    H0 = \"Duration Between Exceedances have no memory (Weibull b=1 = Exponential)\"\n",
    "    #i.e. whether we fail to reject the alternative in the LR test that b=1 (hence correct model)\n",
    "    if LRp<(1-conf_level): \n",
    "        decision = \"Reject H0\"\n",
    "    else: decision = \"Fail to Reject H0\"\n",
    "    \n",
    "    answer = {\"weibull exponential\":b,\n",
    "              \"unrestricted log-likelihood\":uLL,\n",
    "              \"restricted log-likelihood\":rLL,\n",
    "              \"log-likelihood\":LR,\n",
    "              \"log-likelihood ratio test statistic\":LRp,\n",
    "              \"null hypothesis\":H0,\n",
    "              \"decision\":decision}\n",
    "    \n",
    "    return answer\n",
    "\n",
    "def failure_rate(violations):\n",
    "    TN = len(violations)\n",
    "    N = violations.sum()\n",
    "    print(f\"Failure rate of {round((N/TN)*100,2)}%\")\n",
    "    return N/TN\n",
    "\n",
    "def kupiec_test(violations, var_conf_level=0.99, conf_level=0.95):\n",
    "   \n",
    "    '''Perform Kupiec Test (1995).\n",
    "       The main goal is to verify if the number of violations, i.e. proportion of failures, is consistent with the\n",
    "       violations predicted by the model.\n",
    "       \n",
    "        Parameters:\n",
    "            violations (series):    series of violations of VaR\n",
    "            var_conf_level (float): VaR confidence level\n",
    "            conf_level (float):     test confidence level\n",
    "        Returns:\n",
    "            answer (dict):          statistics and decision of the test\n",
    "    '''\n",
    "    if isinstance(violations, pd.core.series.Series):\n",
    "        v = violations[violations==1].count()\n",
    "    elif isinstance(violations, pd.core.frame.DataFrame):\n",
    "        v = violations[violations==1].count().values[0]\n",
    "\n",
    "    N = violations.shape[0]\n",
    "    theta= 1-(v/N)\n",
    "\n",
    "    if v < 0.001:\n",
    "        V = -2*np.log((1-(v/N))**(N))\n",
    "    else:\n",
    "        part1 = ((1-var_conf_level)**(v)) * (var_conf_level**(N-v))\n",
    "        \n",
    "        part11= ((1-theta)**(v)) * (theta**(N-v))\n",
    "        \n",
    "        fact = math.factorial(N) / ( math.factorial(v) * math.factorial(N-v))\n",
    "        \n",
    "        num1 = part1 * fact\n",
    "        den1 = part11 * fact \n",
    "    \n",
    "        V = -2*(np.log(num1/den1))\n",
    "    \n",
    "    chi_square_test = chi2.cdf(V,1) #one degree of freedom\n",
    "    \n",
    "    if chi_square_test < conf_level: result = \"Fail to reject H0\"\n",
    "    elif v==0 and N<=255 and var_conf_level==0.99: result = \"Fail to reject H0\"\n",
    "    else: result = \"Reject H0\"\n",
    "        \n",
    "    return {\"statictic test\":V, \"chi square value\":chi_square_test, \n",
    "            \"null hypothesis\": f\"Probability of failure is {round(1-var_conf_level,3)}\",\n",
    "            \"result\":result}\n",
    "\n",
    "def berkowtiz_tail_test(pnl, volatility_window=252, \n",
    "                        var_conf_level=0.99, conf_level=0.95, random_seed=443):\n",
    "    '''Perform Berkowitz Test (2001).\n",
    "        The goal is to verify if conditional distributions of returns \"GARCH(1,1)\" \n",
    "        used in the VaR Model is adherent to the data.\n",
    "        In this specific test, we do not observe the whole data, only the tail.\n",
    "        \n",
    "        Parameters:\n",
    "            data (dataframe):        pnl (distribution of profit and loss) or return\n",
    "            volatility_window (int): window to cabibrate volatility GARCH model\n",
    "            var_conf_level (float):  VaR confidence level\n",
    "            conf_level (float):      test confidence level\n",
    "            random_seed (int):       integer value to set seed to random values of the optimizer\n",
    "        Returns:\n",
    "            answer (dict):           statistics and decision of the test\n",
    "    '''\n",
    "        \n",
    "    print(\"Normalizing returns...\")\n",
    "    conditional_vol, conditional_mean = pd.DataFrame(), pd.DataFrame()\n",
    "    for t in tqdm(range(pnl.shape[0]-volatility_window+1)):\n",
    "        am = arch.arch_model(pnl[(t):(volatility_window+t)], vol='garch', dist=\"Normal\", rescale=False).fit(disp=\"off\")\n",
    "        cond_vol = am.forecast(horizon=1, reindex=False).variance.apply(np.sqrt)\n",
    "        cond_mean = am.forecast(horizon=1, reindex=False).mean\n",
    "        conditional_vol = pd.concat([conditional_vol, cond_vol])\n",
    "        conditional_mean = pd.concat([conditional_mean, cond_mean])\n",
    "    \n",
    "    ret_padr = ((pnl.values - conditional_mean.values) / conditional_vol.values)\n",
    "        \n",
    "    zeta = stats.norm.ppf(stats.norm.cdf(ret_padr))\n",
    "\n",
    "    alpha=1-var_conf_level\n",
    "    significance = 1-conf_level\n",
    "    \n",
    "    def objective(x):\n",
    "        #pars[0] => media\n",
    "        #pars[1] => vol incondicional\n",
    "        p1 = zeta[np.where(zeta<stats.norm.ppf((alpha)))]\n",
    "        p2 = zeta[np.where(zeta>=stats.norm.ppf(alpha))]*0 + stats.norm.ppf(alpha)\n",
    "        return -( sum(np.log(stats.norm.pdf((p1-x[0])/x[1])/x[1])) + sum( np.log(1-stats.norm.cdf((p2 - x[0])/x[1]) )) )\n",
    "        \n",
    "    print(\"Optimizing...\")\n",
    "    start = time.time()\n",
    "    optimum_result = pygosolnp.solve(\n",
    "                            obj_func=objective,\n",
    "                            par_lower_limit=[-10, 0.01],\n",
    "                            par_upper_limit=[10, 3],\n",
    "                            number_of_simulations=200,  # This represents the number of starting guesses to use\n",
    "                            number_of_restarts=20,  # This specifies how many restarts to run from the best starting guesses\n",
    "                            number_of_processes=None,  # None here means to run everything single-processed\n",
    "                            seed=random_seed,  # Seed for reproducibility, if omitted the default random seed is used (typically cpu clock based)\n",
    "                            pysolnp_max_major_iter=100,  # Pysolnp property\n",
    "                            debug=False)\n",
    "    print(\"\")\n",
    "    print(f\"Elapsed time: {time.time() - start} s\")\n",
    "    \n",
    "    #all_results = optimum_result.all_results\n",
    "    #print(\"; \".join([f\"Solution {index + 1}: {solution.obj_value}\" for index, solution in enumerate(all_results)]))\n",
    "    best_solution = optimum_result.best_solution\n",
    "    #print(f\"Best solution {best_solution.obj_value} for parameters {best_solution.parameters}.\")\n",
    "    \n",
    "    uLL = -best_solution.obj_value\n",
    "    rLL = -objective([0, 1])\n",
    "    LR = 2 * (uLL - rLL)\n",
    "    chid = 1 - stats.chi2.cdf(LR, 2)\n",
    "    if (chid < significance):\n",
    "        decision = \"Reject H0\"\n",
    "    else: decision = \"Fail to Reject H0\"\n",
    "    H0 = \"Distribuition is Normal(0,1)\"\n",
    "    \n",
    "    answer = {\"solution\":best_solution,\n",
    "              \"ull\":uLL,\n",
    "              \"rll\":rLL,\n",
    "              \"LR\":LR,\n",
    "              \"chi square test\":chid,\n",
    "              \"null hypothesis\":H0,\n",
    "              \"decision\":decision}\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a4bb49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vartests\n",
      "  Downloading vartests-0.1.9-py3-none-any.whl (43 kB)\n",
      "Requirement already satisfied: pygosolnp<2022.0.0,>=2021.5.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from vartests) (2021.5.1)\n",
      "Requirement already satisfied: arch<6.0.0,>=5.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from vartests) (5.2.0)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.3.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from vartests) (1.3.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.62.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from vartests) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from arch<6.0.0,>=5.0.1->vartests) (1.20.3)\n",
      "Requirement already satisfied: statsmodels>=0.11 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from arch<6.0.0,>=5.0.1->vartests) (0.13.2)\n",
      "Requirement already satisfied: scipy>=1.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from arch<6.0.0,>=5.0.1->vartests) (1.7.1)\n",
      "Requirement already satisfied: property-cached>=1.6.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from arch<6.0.0,>=5.0.1->vartests) (1.6.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas<2.0.0,>=1.3.4->vartests) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas<2.0.0,>=1.3.4->vartests) (2.8.2)\n",
      "Requirement already satisfied: pysolnp in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pygosolnp<2022.0.0,>=2021.5.1->vartests) (2022.3.13)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas<2.0.0,>=1.3.4->vartests) (1.16.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from statsmodels>=0.11->arch<6.0.0,>=5.0.1->vartests) (21.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from statsmodels>=0.11->arch<6.0.0,>=5.0.1->vartests) (0.5.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from packaging>=21.3->statsmodels>=0.11->arch<6.0.0,>=5.0.1->vartests) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.62.3->vartests) (0.4.4)\n",
      "Installing collected packages: vartests\n",
      "Successfully installed vartests-0.1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install vartests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f2f0b15",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Example.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2364/3809700539.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Example.xlsx\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mviolations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Violations\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpnl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"PnL\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         raise ValueError(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1189\u001b[0m                 \u001b[0mext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xls\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m                 ext = inspect_excel_format(\n\u001b[0m\u001b[0;32m   1192\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m                 )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1068\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1070\u001b[1;33m     with get_handle(\n\u001b[0m\u001b[0;32m   1071\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m     ) as handle:\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Example.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel(\"Example.xlsx\", index_col=0)\n",
    "violations = data[\"Violations\"]\n",
    "pnl = data[\"PnL\"] \n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197aa06e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
